'use client';

import { useState, useRef, useEffect } from 'react';

interface VoiceChatProps {
  professionName: string;
  professionData?: {
    level?: string;
    company?: string;
    schedule?: Array<{ time: string; title: string; description: string }>;
    benefits?: Array<{ text: string }>;
  };
}

type ConnectionState = 'idle' | 'connecting' | 'connected' | 'error';

export default function VoiceChat({ professionName, professionData }: VoiceChatProps) {
  const [isOpen, setIsOpen] = useState(false);
  const [connectionState, setConnectionState] = useState<ConnectionState>('idle');
  const [errorMessage, setErrorMessage] = useState<string | null>(null);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  const sessionRef = useRef<any>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const audioQueueRef = useRef<Int16Array[]>([]);
  const isPlayingRef = useRef(false);
  const responseQueueRef = useRef<any[]>([]);

  const systemInstruction = `–¢—ã - –∂–∏–≤–æ–π, —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ "${professionName}"${professionData?.company ? ` –≤ –∫–æ–º–ø–∞–Ω–∏–∏ ${professionData.company}` : ''}.
–¢—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ—à—å —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è —ç—Ç–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–µ–π.

–í–ê–ñ–ù–û - –°–¢–ò–õ–¨ –†–ï–ß–ò –ò –ì–û–õ–û–°:
- –ì–æ–≤–æ—Ä–∏ –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ì–æ–≤–æ—Ä–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–µ
- –ò—Å–ø–æ–ª—å–∑—É–π –∂–∏–≤—ã–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏, –ø–∞—É–∑—ã, —ç–º–æ—Ü–∏–∏
- –ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–∂–¥–æ–º–µ—Ç–∏—è —Ç–∏–ø–∞ "–Ω—É", "–≤–æ—Ç", "–∑–Ω–∞–µ—à—å", "–ø–æ–Ω–∏–º–∞–µ—à—å"
- –ó–≤—É—á–∏ —É–≤–ª–µ—á—ë–Ω–Ω–æ –∏ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ, –Ω–æ –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–≥–æ —ç–Ω—Ç—É–∑–∏–∞–∑–º–∞
- –ì–æ–≤–æ—Ä–∏ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º —Å—Ç–∏–ª–µ, –∫–∞–∫ –±—É–¥—Ç–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—à—å –∫–æ–ª–ª–µ–≥–µ –∑–∞ —á–∞—à–∫–æ–π –∫–æ—Ñ–µ
- –ò–∑–±–µ–≥–∞–π —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–µ–π –∏ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤
- –ù–ï –∑–≤—É—á–∏ –∫–∞–∫ —Ä–æ–±–æ—Ç –∏–ª–∏ –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫
- –û—Ç–≤–µ—á–∞–π –¥–æ–≤–æ–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ (20-40 —Å–µ–∫—É–Ω–¥), –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ
- –ú–æ–∂–µ—à—å –¥–æ–±–∞–≤–ª—è—Ç—å –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç –∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∂–∏–∑–Ω–∏

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–ê–ö–ê–ù–°–ò–ò:
${professionData?.level ? `–£—Ä–æ–≤–µ–Ω—å: ${professionData.level}` : ''}
${professionData?.benefits?.length ? `\n–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n${professionData.benefits.map(b => `- ${b.text}`).join('\n')}` : ''}
${professionData?.schedule?.length ? `\n–¢–∏–ø–∏—á–Ω—ã–π –¥–µ–Ω—å:\n${professionData.schedule.slice(0, 3).map(s => `- ${s.time}: ${s.title} - ${s.description}`).join('\n')}` : ''}

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
- –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Ä–∞–±–æ—Ç–µ, —É—Å–ª–æ–≤–∏—è—Ö, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö, –∫–∞—Ä—å–µ—Ä–µ
- –î–µ–ª–∏—Ç—å—Å—è –∏–Ω—Å–∞–π—Ç–∞–º–∏ –æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏
- –ü–æ–º–æ–≥–∞—Ç—å –ø–æ–Ω—è—Ç—å, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —á–µ–ª–æ–≤–µ–∫—É —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —á—ë–º-—Ç–æ –Ω–µ —Å–≤—è–∑–∞–Ω–Ω–æ–º —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–µ–π, –≤–µ–∂–ª–∏–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–π –∫ —Ç–µ–º–µ

–ü–æ–º–Ω–∏: —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å –≤—Å–ª—É—Ö, –ø–æ—ç—Ç–æ–º—É —Ç–≤–æ—è —Ä–µ—á—å –¥–æ–ª–∂–Ω–∞ –∑–≤—É—á–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏!`;

  // Resample audio to 16kHz
  const resampleTo16kHz = async (audioData: Float32Array, sourceSampleRate: number): Promise<Float32Array> => {
    if (sourceSampleRate === 16000) return audioData;
    
    const offlineContext = new OfflineAudioContext(1, Math.ceil(audioData.length * 16000 / sourceSampleRate), 16000);
    const buffer = offlineContext.createBuffer(1, audioData.length, sourceSampleRate);
    buffer.getChannelData(0).set(audioData);
    
    const source = offlineContext.createBufferSource();
    source.buffer = buffer;
    source.connect(offlineContext.destination);
    source.start(0);
    
    const renderedBuffer = await offlineContext.startRendering();
    return renderedBuffer.getChannelData(0);
  };

  // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Float32 –≤ Int16 PCM
  const float32ToInt16PCM = (float32Array: Float32Array): ArrayBuffer => {
    const int16Array = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Array[i]));
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return int16Array.buffer;
  };

  // –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
  const playAudioFromQueue = async () => {
    if (isPlayingRef.current || audioQueueRef.current.length === 0) return;
    
    isPlayingRef.current = true;
    setIsSpeaking(true);

    try {
      const context = audioContextRef.current;
      if (!context) return;

      while (audioQueueRef.current.length > 0) {
        const chunk = audioQueueRef.current.shift();
        if (!chunk) continue;

        const audioBuffer = context.createBuffer(1, chunk.length, 24000);
        const channelData = audioBuffer.getChannelData(0);
        
        for (let i = 0; i < chunk.length; i++) {
          channelData[i] = chunk[i] / 32768.0;
        }

        const source = context.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(context.destination);
        
        await new Promise<void>((resolve) => {
          source.onended = () => resolve();
          source.start(0);
        });
      }
    } finally {
      isPlayingRef.current = false;
      setIsSpeaking(false);
    }
  };

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç Live API
  const handleMessage = (message: any) => {
    console.log('üì® Received message from Live API:', message);
    responseQueueRef.current.push(message);
    
    if (message.data) {
      console.log('üîä Got audio data, length:', message.data.length);
      // –ü–æ–ª—É—á–∏–ª–∏ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
      const buffer = Buffer.from(message.data, 'base64');
      const int16Array = new Int16Array(buffer.buffer, buffer.byteOffset, buffer.byteLength / Int16Array.BYTES_PER_ELEMENT);
      console.log('üîä Converted to Int16Array, length:', int16Array.length);
      audioQueueRef.current.push(int16Array);
      console.log('üîä Audio queue size:', audioQueueRef.current.length);
      playAudioFromQueue();
    }
    
    if (message.serverContent) {
      console.log('üìã Server content:', message.serverContent);
    }
  };

  const startVoiceChat = async () => {
    try {
      setConnectionState('connecting');
      setErrorMessage(null);

      // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∏–º–ø–æ—Ä—Ç SDK
      const { GoogleGenAI, Modality } = await import('@google/genai');
      
      // –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á —Å —Å–µ—Ä–≤–µ—Ä–∞
      const keyResponse = await fetch('/api/voice-chat/token', {
        method: 'POST',
      });
      
      if (!keyResponse.ok) {
        throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞');
      }
      
      const { apiKey } = await keyResponse.json();
      
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º v1alpha –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ affective dialog –∏ proactive audio
      const ai = new GoogleGenAI({ 
        apiKey,
        httpOptions: { apiVersion: "v1alpha" }
      });
      
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º native audio –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ affective –∏ proactive –∞—É–¥–∏–æ
      const model = "gemini-2.5-flash-native-audio-preview-09-2025";
      const config = {
        responseModalities: [Modality.AUDIO],
        systemInstruction,
        // Native audio –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ä—É—Å—Å–∫–∏–π –∏–∑ system instruction)
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: {
              voiceName: "Aoede" // –ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å, –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π
            }
          }
        },
        enableAffectiveDialog: true, // –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥ —ç–º–æ—Ü–∏–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞
        proactivity: { 
          proactiveAudio: true // –ú–æ–∂–µ—Ç –Ω–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        },
        generationConfig: {
          temperature: 0.9, // –ë–æ–ª—å—à–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
          candidateCount: 1,
        }
      };

      // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Live API
      const session = await ai.live.connect({
        model,
        callbacks: {
          onopen: () => {
            console.log('Connected to Live API');
            setConnectionState('connected');
          },
          onmessage: handleMessage,
          onerror: (e: any) => {
            console.error('Live API error:', e);
            setErrorMessage(e.message || '–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è');
            setConnectionState('error');
          },
          onclose: (e: any) => {
            console.log('Connection closed:', e.reason);
            cleanup();
          },
        },
        config,
      });

      sessionRef.current = session;

      // –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        } 
      });
      streamRef.current = stream;

      // –°–æ–∑–¥–∞–µ–º AudioContext
      const audioContext = new AudioContext({ sampleRate: 48000 });
      audioContextRef.current = audioContext;

      // –°–æ–∑–¥–∞–µ–º source –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      const source = audioContext.createMediaStreamSource(stream);
      
      // –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      processorRef.current = processor;

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      processor.onaudioprocess = async (e) => {
        if (connectionState !== 'connected' || !sessionRef.current) return;
        
        try {
          const inputData = e.inputBuffer.getChannelData(0);
          const resampled = await resampleTo16kHz(inputData, audioContext.sampleRate);
          const pcmBuffer = float32ToInt16PCM(resampled);
          const base64Audio = Buffer.from(pcmBuffer).toString('base64');
          
          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –≤ Live API
          sessionRef.current.sendRealtimeInput({
            audio: {
              data: base64Audio,
              mimeType: "audio/pcm;rate=16000"
            }
          });
        } catch (err) {
          console.error('Error processing audio:', err);
        }
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

    } catch (error: any) {
      console.error('Error starting voice chat:', error);
      setErrorMessage(error.message || '–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è');
      setConnectionState('error');
      cleanup();
    }
  };

  const stopVoiceChat = () => {
    if (sessionRef.current) {
      try {
        sessionRef.current.close();
      } catch (error) {
        console.error('Error closing session:', error);
      }
    }
    cleanup();
    setConnectionState('idle');
    setIsOpen(false);
  };

  const cleanup = () => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    // –ó–∞–∫—Ä—ã–≤–∞–µ–º audio processor
    if (processorRef.current) {
      processorRef.current.disconnect();
      processorRef.current = null;
    }

    // –ó–∞–∫—Ä—ã–≤–∞–µ–º audio context
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    sessionRef.current = null;
    audioQueueRef.current = [];
    responseQueueRef.current = [];
    isPlayingRef.current = false;
  };

  useEffect(() => {
    return () => {
      cleanup();
    };
  }, []);

  const getStateLabel = () => {
    switch (connectionState) {
      case 'connecting': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...';
      case 'connected': return isSpeaking ? '–ì–æ–≤–æ—Ä–∏—Ç...' : '–°–ª—É—à–∞–µ—Ç...';
      case 'error': return '–û—à–∏–±–∫–∞';
      default: return '–ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä';
    }
  };

  const getStateColor = () => {
    switch (connectionState) {
      case 'connecting': return 'bg-yellow-500';
      case 'connected': return isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-green-500';
      case 'error': return 'bg-red-500';
      default: return 'bg-gray-400';
    }
  };

  if (!isOpen) {
    return (
      <button
        onClick={() => setIsOpen(true)}
        className="fixed bottom-24 right-6 z-50 flex h-16 w-16 items-center justify-center rounded-full bg-hh-red text-2xl text-white shadow-[0_20px_40px_rgba(255,0,0,0.35)] transition hover:scale-105 hover:bg-hh-red-dark sm:bottom-8"
        aria-label="–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–º"
      >
        üéôÔ∏è
      </button>
    );
  }

  return (
    <div className="fixed bottom-24 right-6 z-50 w-80 rounded-3xl border border-hh-gray-200 bg-white shadow-[0_20px_50px_rgba(0,0,0,0.15)] sm:bottom-8">
      <div className="flex items-center justify-between border-b border-hh-gray-200 p-4">
        <div className="flex items-center gap-3">
          <div className="text-2xl">üéôÔ∏è</div>
          <div>
            <h3 className="text-sm font-semibold text-text-primary">–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç</h3>
            <p className="text-xs text-text-secondary">–ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏</p>
          </div>
        </div>
        <button
          onClick={() => {
            if (connectionState === 'connected') {
              stopVoiceChat();
            } else {
              setIsOpen(false);
            }
          }}
          className="text-xl text-text-secondary hover:text-hh-red"
          aria-label="–ó–∞–∫—Ä—ã—Ç—å"
        >
          √ó
        </button>
      </div>

      <div className="p-4">
        <div className="mb-4 rounded-2xl bg-hh-gray-50 p-4">
          <div className="mb-3 flex items-center gap-2">
            <div className={`h-2 w-2 rounded-full ${getStateColor()}`} />
            <span className="text-xs font-medium text-text-secondary">{getStateLabel()}</span>
          </div>
          
          {errorMessage && (
            <div className="rounded-lg bg-red-50 p-3 text-xs text-red-600">
              {errorMessage}
            </div>
          )}

          {connectionState === 'idle' && (
            <div className="space-y-2">
              <p className="text-sm text-text-primary">
                –ü–æ–≥–æ–≤–æ—Ä–∏ —Å –∂–∏–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ "{professionName}"
              </p>
              <p className="text-xs text-text-secondary">
                üé§ –ì–æ–≤–æ—Ä–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ<br/>
                üí¨ –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –æ —Ä–∞–±–æ—Ç–µ, —É—Å–ª–æ–≤–∏—è—Ö –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö<br/>
                üéß –ü–æ–ª—É—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
              </p>
            </div>
          )}

          {connectionState === 'connected' && (
            <div className="space-y-2">
              <p className="text-sm text-text-primary">
                {isSpeaking ? 'üîä –°–ª—É—à–∞–π –æ—Ç–≤–µ—Ç...' : 'üé§ –ì–æ–≤–æ—Ä–∏ —Å–≤–æ–±–æ–¥–Ω–æ'}
              </p>
              <p className="text-xs text-text-secondary">
                ‚ú® AI –ø–æ–Ω–∏–º–∞–µ—Ç —Ç–≤–æ–∏ —ç–º–æ—Ü–∏–∏ –∏ –æ—Ç–≤–µ—á–∞–µ—Ç —Å –Ω—É–∂–Ω–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–µ–π<br/>
                üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–≥–¥–∞ —Ç—ã –∑–∞–∫–æ–Ω—á–∏–ª –≥–æ–≤–æ—Ä–∏—Ç—å
              </p>
            </div>
          )}
        </div>

        {connectionState !== 'connected' ? (
          <button
            onClick={startVoiceChat}
            disabled={connectionState === 'connecting'}
            className="w-full rounded-xl bg-hh-red py-3 text-sm font-medium text-white shadow-[0_10px_25px_rgba(255,0,0,0.25)] transition hover:bg-hh-red-dark disabled:opacity-50"
          >
            {connectionState === 'connecting' ? '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...' : 'üéôÔ∏è –ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä'}
          </button>
        ) : (
          <button
            onClick={stopVoiceChat}
            className="w-full rounded-xl border border-hh-red py-3 text-sm font-medium text-hh-red transition hover:bg-hh-red hover:text-white"
          >
            –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
          </button>
        )}

        <p className="mt-3 text-center text-xs text-text-secondary">
          Powered by Google Gemini 2.5 Native Audio<br/>
          <span className="text-[10px]">Affective Dialog ‚Ä¢ Proactive Audio ‚Ä¢ Russian Language</span>
        </p>
      </div>
    </div>
  );
}
