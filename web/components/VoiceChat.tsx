'use client';

import { useState, useRef, useEffect } from 'react';
import { io, Socket } from 'socket.io-client';

interface VoiceChatProps {
  professionName: string;
  professionData?: {
    level?: string;
    company?: string;
    schedule?: Array<{ time: string; title: string; description: string }>;
    skills?: Array<{ name: string; level: number }>;
    benefits?: Array<{ text: string }>;
  };
}

type ConnectionState = 'idle' | 'connecting' | 'connected' | 'error';

export default function VoiceChat({ professionName, professionData }: VoiceChatProps) {
  const [isOpen, setIsOpen] = useState(false);
  const [connectionState, setConnectionState] = useState<ConnectionState>('idle');
  const [errorMessage, setErrorMessage] = useState<string | null>(null);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  const socketRef = useRef<Socket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const audioQueueRef = useRef<Int16Array[]>([]);
  const isPlayingRef = useRef(false);

  // Resample audio to 16kHz
  const resampleTo16kHz = async (audioData: Float32Array, sourceSampleRate: number): Promise<Float32Array> => {
    if (sourceSampleRate === 16000) return audioData;
    
    const offlineContext = new OfflineAudioContext(1, Math.ceil(audioData.length * 16000 / sourceSampleRate), 16000);
    const buffer = offlineContext.createBuffer(1, audioData.length, sourceSampleRate);
    buffer.getChannelData(0).set(audioData);
    
    const source = offlineContext.createBufferSource();
    source.buffer = buffer;
    source.connect(offlineContext.destination);
    source.start(0);
    
    const renderedBuffer = await offlineContext.startRendering();
    return renderedBuffer.getChannelData(0);
  };

  // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Float32 –≤ Int16 PCM
  const float32ToInt16PCM = (float32Array: Float32Array): ArrayBuffer => {
    const int16Array = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Array[i]));
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return int16Array.buffer;
  };

  // –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
  const playAudioFromQueue = async () => {
    if (isPlayingRef.current || audioQueueRef.current.length === 0) return;
    
    isPlayingRef.current = true;
    setIsSpeaking(true);

    try {
      const context = audioContextRef.current;
      if (!context) return;

      while (audioQueueRef.current.length > 0) {
        const chunk = audioQueueRef.current.shift();
        if (!chunk) continue;

        const audioBuffer = context.createBuffer(1, chunk.length, 24000);
        const channelData = audioBuffer.getChannelData(0);
        
        for (let i = 0; i < chunk.length; i++) {
          channelData[i] = chunk[i] / 32768.0;
        }

        const source = context.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(context.destination);
        
        await new Promise<void>((resolve) => {
          source.onended = () => resolve();
          source.start(0);
        });
      }
    } finally {
      isPlayingRef.current = false;
      setIsSpeaking(false);
    }
  };

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ (Gemini —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏)
  const handleGeminiMessage = (message: any) => {
    console.log('üì® Received message from Gemini (via server):', message);
    
    if (message.data) {
      console.log('üîä Got audio data, length:', message.data.length);
      // –ü–æ–ª—É—á–∏–ª–∏ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
      const buffer = Buffer.from(message.data, 'base64');
      const int16Array = new Int16Array(buffer.buffer, buffer.byteOffset, buffer.byteLength / Int16Array.BYTES_PER_ELEMENT);
      console.log('üîä Converted to Int16Array, length:', int16Array.length);
      audioQueueRef.current.push(int16Array);
      console.log('üîä Audio queue size:', audioQueueRef.current.length);
      playAudioFromQueue();
    }
    
    if (message.serverContent) {
      console.log('üìã Server content:', message.serverContent);
    }
  };

  const startVoiceChat = async () => {
    try {
      setConnectionState('connecting');
      setErrorMessage(null);

      // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –Ω–∞—à–µ–º—É WebSocket —Å–µ—Ä–≤–µ—Ä—É (Server-to-Server)
      const wsUrl = process.env.NEXT_PUBLIC_WS_URL || 'http://localhost:3001';
      console.log('üîå Connecting to WebSocket server:', wsUrl);
      
      const socket = io(wsUrl, {
        transports: ['websocket', 'polling'],
        reconnection: true,
        reconnectionDelay: 1000,
        reconnectionAttempts: 5
      });

      socketRef.current = socket;

      // –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ Socket.IO
      socket.on('connect', () => {
        console.log('‚úÖ Connected to WebSocket server');
        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Gemini —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–µ—Ä
        socket.emit('init', {
          professionName,
          professionData
        });
      });

      socket.on('connected', () => {
        console.log('‚úÖ Gemini Live API connected via server');
        setConnectionState('connected');
      });

      socket.on('gemini-message', handleGeminiMessage);

      socket.on('error', (data: any) => {
        console.error('‚ùå Server error:', data);
        setErrorMessage(data.message || '–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞');
        setConnectionState('error');
      });

      socket.on('disconnected', (data: any) => {
        console.log('üî¥ Disconnected:', data.reason);
        cleanup();
      });

      socket.on('disconnect', () => {
        console.log('üî¥ Socket disconnected');
        setConnectionState('idle');
      });

      socket.on('connect_error', (error: any) => {
        console.error('‚ùå Connection error:', error);
        setErrorMessage('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É');
        setConnectionState('error');
      });

      // –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        } 
      });
      streamRef.current = stream;

      // –°–æ–∑–¥–∞–µ–º AudioContext
      const audioContext = new AudioContext({ sampleRate: 48000 });
      audioContextRef.current = audioContext;

      // –°–æ–∑–¥–∞–µ–º source –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      const source = audioContext.createMediaStreamSource(stream);
      
      // –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      processorRef.current = processor;

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      processor.onaudioprocess = async (e) => {
        if (connectionState !== 'connected' || !socketRef.current) return;
        
        try {
          const inputData = e.inputBuffer.getChannelData(0);
          const resampled = await resampleTo16kHz(inputData, audioContext.sampleRate);
          const pcmBuffer = float32ToInt16PCM(resampled);
          const base64Audio = Buffer.from(pcmBuffer).toString('base64');
          
          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ –Ω–∞—à —Å–µ—Ä–≤–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–µ—Å—ã–ª–∞–µ—Ç –≤ Gemini
          socketRef.current.emit('audio', {
            audio: base64Audio,
            mimeType: "audio/pcm;rate=16000"
          });
        } catch (err) {
          console.error('Error processing audio:', err);
        }
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

    } catch (error: any) {
      console.error('Error starting voice chat:', error);
      setErrorMessage(error.message || '–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è');
      setConnectionState('error');
      cleanup();
    }
  };

  const stopVoiceChat = () => {
    if (socketRef.current) {
      try {
        socketRef.current.emit('close');
        socketRef.current.disconnect();
      } catch (error) {
        console.error('Error closing socket:', error);
      }
    }
    cleanup();
    setConnectionState('idle');
    setIsOpen(false);
  };

  const cleanup = () => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    // –ó–∞–∫—Ä—ã–≤–∞–µ–º audio processor
    if (processorRef.current) {
      processorRef.current.disconnect();
      processorRef.current = null;
    }

    // –ó–∞–∫—Ä—ã–≤–∞–µ–º audio context
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (socketRef.current) {
      socketRef.current.disconnect();
      socketRef.current = null;
    }

    audioQueueRef.current = [];
    isPlayingRef.current = false;
  };

  useEffect(() => {
    return () => {
      cleanup();
    };
  }, []);

  const getStateLabel = () => {
    switch (connectionState) {
      case 'connecting': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...';
      case 'connected': return isSpeaking ? '–ì–æ–≤–æ—Ä–∏—Ç...' : '–°–ª—É—à–∞–µ—Ç...';
      case 'error': return '–û—à–∏–±–∫–∞';
      default: return '–ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä';
    }
  };

  const getStateColor = () => {
    switch (connectionState) {
      case 'connecting': return 'bg-yellow-500';
      case 'connected': return isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-green-500';
      case 'error': return 'bg-red-500';
      default: return 'bg-gray-400';
    }
  };

  if (!isOpen) {
    return (
      <button
        onClick={() => setIsOpen(true)}
        className="fixed bottom-24 right-6 z-50 flex h-16 w-16 items-center justify-center rounded-full bg-hh-red text-2xl text-white shadow-[0_20px_40px_rgba(255,0,0,0.35)] transition hover:scale-105 hover:bg-hh-red-dark sm:bottom-8"
        aria-label="–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–º"
      >
        üéôÔ∏è
      </button>
    );
  }

  return (
    <div className="fixed bottom-24 right-6 z-50 w-80 rounded-3xl border border-hh-gray-200 bg-white shadow-[0_20px_50px_rgba(0,0,0,0.15)] sm:bottom-8">
      <div className="flex items-center justify-between border-b border-hh-gray-200 p-4">
        <div className="flex items-center gap-3">
          <div className="text-2xl">üéôÔ∏è</div>
          <div>
            <h3 className="text-sm font-semibold text-text-primary">–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç</h3>
            <p className="text-xs text-text-secondary">–ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏</p>
          </div>
        </div>
        <button
          onClick={() => {
            if (connectionState === 'connected') {
              stopVoiceChat();
            } else {
              setIsOpen(false);
            }
          }}
          className="text-xl text-text-secondary hover:text-hh-red"
          aria-label="–ó–∞–∫—Ä—ã—Ç—å"
        >
          √ó
        </button>
      </div>

      <div className="p-4">
        <div className="mb-4 rounded-2xl bg-hh-gray-50 p-4">
          <div className="mb-3 flex items-center gap-2">
            <div className={`h-2 w-2 rounded-full ${getStateColor()}`} />
            <span className="text-xs font-medium text-text-secondary">{getStateLabel()}</span>
          </div>
          
          {errorMessage && (
            <div className="rounded-lg bg-red-50 p-3 text-xs text-red-600">
              {errorMessage}
            </div>
          )}

          {connectionState === 'idle' && (
            <div className="space-y-2">
              <p className="text-sm text-text-primary">
                –ü–æ–≥–æ–≤–æ—Ä–∏ —Å –∂–∏–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ "{professionName}"
              </p>
              <p className="text-xs text-text-secondary">
                üé§ –ì–æ–≤–æ—Ä–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ<br/>
                üí¨ –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –æ —Ä–∞–±–æ—Ç–µ, —É—Å–ª–æ–≤–∏—è—Ö –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö<br/>
                üéß –ü–æ–ª—É—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
              </p>
            </div>
          )}

          {connectionState === 'connected' && (
            <div className="space-y-2">
              <p className="text-sm text-text-primary">
                {isSpeaking ? 'üîä –°–ª—É—à–∞–π –æ—Ç–≤–µ—Ç...' : 'üé§ –ì–æ–≤–æ—Ä–∏ —Å–≤–æ–±–æ–¥–Ω–æ'}
              </p>
              <p className="text-xs text-text-secondary">
                ‚ú® AI –ø–æ–Ω–∏–º–∞–µ—Ç —Ç–≤–æ–∏ —ç–º–æ—Ü–∏–∏ –∏ –æ—Ç–≤–µ—á–∞–µ—Ç —Å –Ω—É–∂–Ω–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–µ–π<br/>
                üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–≥–¥–∞ —Ç—ã –∑–∞–∫–æ–Ω—á–∏–ª –≥–æ–≤–æ—Ä–∏—Ç—å
              </p>
            </div>
          )}
        </div>

        {connectionState !== 'connected' ? (
          <button
            onClick={startVoiceChat}
            disabled={connectionState === 'connecting'}
            className="w-full rounded-xl bg-hh-red py-3 text-sm font-medium text-white shadow-[0_10px_25px_rgba(255,0,0,0.25)] transition hover:bg-hh-red-dark disabled:opacity-50"
          >
            {connectionState === 'connecting' ? '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...' : 'üéôÔ∏è –ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä'}
          </button>
        ) : (
          <button
            onClick={stopVoiceChat}
            className="w-full rounded-xl border border-hh-red py-3 text-sm font-medium text-hh-red transition hover:bg-hh-red hover:text-white"
          >
            –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
          </button>
        )}

        <p className="mt-3 text-center text-xs text-text-secondary">
          Powered by Google Gemini 2.5 Native Audio<br/>
          <span className="text-[10px]">Server-to-Server ‚Ä¢ Affective Dialog ‚Ä¢ Russian</span>
        </p>
      </div>
    </div>
  );
}
